**sentence-bert来提取句子向量？word2vec来进行词嵌入？bert来进行词嵌入。**
**这里的词嵌入和句子向量之间的区别是什么？在很多文本分析任务之中，文本特征和句向量、词向量之间的区别是什么？**
- 词嵌入模型有word2vec、bert等，主要用于词级任务。
- 句子向量模型有sentence-bert、bert的[cls],主要用于文本分类，文本相似度计算等任务。
**为什么bert在进行词嵌入之后往往要加一个全连接层？有时候还要加一些特征提取层，比如LSTM、GRU等。这里的特征提取层和全连接层的区别是什么？**
- BERT后加全连接层是为了调整维度和分类。bert的输出是768维的向量，对于分类任务而言，需要把输出调整到分类数目上，这就是全连接层的作用。
- bert后面加入一些特征提取层，比如LSTM、GRU，是为了增强序列建模能力，比如文本生成任务上面。
- 特征提取层主要用于增强复杂建模的能力，加入全连接层主要是为了适配任务。



学习的时候要做**小计划**，可以清楚自己将要在接下来的一小段时间里干什么工作。
克服拖延症可以使用**两分钟起跑法**克服冷启动问题。先设置一个两分钟的计时器，决定在这两分钟之内具体需要做的事情，计时结束后做决定：
1. 不限时地继续做这件事
2. 计时两分钟去做其他事情
3. 停止做事，休息娱乐